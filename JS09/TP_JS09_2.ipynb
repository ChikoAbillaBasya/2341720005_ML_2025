{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "937d2054",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/drive/1sBdRzNt-fn61kF3I_I6yLY11I3HSQk8M?usp=drive_link\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6397b99",
   "metadata": {},
   "source": [
    "# **Tugas 2**\n",
    "---\n",
    "* Buatlah model klasfikasi Multinomial Naive Bayes dengan ketentuan,\n",
    "1. Menggunakan data `spam.csv`\n",
    "2. Fitur `CountVectorizer` dengan mengaktifkan **stop_words**\n",
    "3. Evaluasi hasilnya\n",
    "\n",
    "* Buatlah model klasfikasi Multinomial Naive Bayes dengan ketentuan,\n",
    "1. Menggunakan data `spam.csv`\n",
    "2. Fitur `TF-IDF` dengan mengaktifkan **stop_words**\n",
    "3. Evaluasi hasilnya dan bandingkan dengan hasil pada Tugas no 2.\n",
    "4. Berikan kesimpulan fitur mana yang terbaik pada kasus data `spam.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb9141d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MultinomialNB + CountVectorizer(stop_words='english') ===\n",
      "Akurasi      : 0.9839\n",
      "F1 (spam)    : 0.9384\n",
      "Precision(spam): 0.9580\n",
      "Recall  (spam): 0.9195\n",
      "F1 (macro)   : 0.9645\n",
      "Confusion Matrix [rows=true, cols=pred] (labels=['ham','spam']):\n",
      "[[960   6]\n",
      " [ 12 137]]\n",
      "\n",
      "Classification Report:\n",
      "              precision  recall  f1-score   support\n",
      "ham               0.988   0.994     0.991   966.000\n",
      "spam              0.958   0.919     0.938   149.000\n",
      "accuracy          0.984   0.984     0.984     0.984\n",
      "macro avg         0.973   0.957     0.965  1115.000\n",
      "weighted avg      0.984   0.984     0.984  1115.000\n",
      "\n",
      "=== MultinomialNB + TfidfVectorizer(stop_words='english') ===\n",
      "Akurasi      : 0.9686\n",
      "F1 (spam)    : 0.8669\n",
      "Precision(spam): 1.0000\n",
      "Recall  (spam): 0.7651\n",
      "F1 (macro)   : 0.9246\n",
      "Confusion Matrix [rows=true, cols=pred] (labels=['ham','spam']):\n",
      "[[966   0]\n",
      " [ 35 114]]\n",
      "\n",
      "Classification Report:\n",
      "              precision  recall  f1-score   support\n",
      "ham               0.965   1.000     0.982   966.000\n",
      "spam              1.000   0.765     0.867   149.000\n",
      "accuracy          0.969   0.969     0.969     0.969\n",
      "macro avg         0.983   0.883     0.925  1115.000\n",
      "weighted avg      0.970   0.969     0.967  1115.000\n",
      "\n",
      "=== Perbandingan & Kesimpulan ===\n",
      "F1(spam) CountVectorizer: 0.9384 | TF-IDF: 0.8669 | Pilihan terbaik (berdasarkan F1 kelas spam): CountVectorizer\n",
      "Akurasi     CountVectorizer: 0.9839 | TF-IDF: 0.9686\n",
      "F1(macro)   CountVectorizer: 0.9645 | TF-IDF: 0.9246\n",
      "\n",
      "Catatan:\n",
      "- Multinomial Naive Bayes secara teori lebih cocok untuk fitur berbasis frekuensi/count (CountVectorizer),\n",
      "  sehingga sering kali CountVectorizer memberi F1 spam sedikit lebih baik daripada TF-IDF.\n",
      "- Namun, hasil aktual bisa berbeda tergantung split data. Gunakan cross-validation untuk gambaran lebih stabil.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "@dataclass\n",
    "class EvalResult:\n",
    "    name: str\n",
    "    accuracy: float\n",
    "    f1_spam: float\n",
    "    precision_spam: float\n",
    "    recall_spam: float\n",
    "    f1_macro: float\n",
    "    report: Dict\n",
    "    confusion: np.ndarray\n",
    "\n",
    "\n",
    "def load_spam_dataset(csv_path: str = \"sample_data/spam.csv\") -> Tuple[pd.Series, pd.Series]:\n",
    "    \"\"\"\n",
    "    Memuat dataset SMS Spam Collection dari spam.csv yang memiliki kolom:\n",
    "    - v1: label ('ham'/'spam')\n",
    "    - v2: teks/pesan\n",
    "    Beberapa versi dataset punya kolom kosong tambahan; kita pilih hanya v1 dan v2.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"File '{csv_path}' tidak ditemukan. Pastikan file ada di direktori kerja.\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Banyak versi dataset ini memakai encoding latin-1 dan punya kolom kosong.\n",
    "    df = pd.read_csv(csv_path, encoding=\"latin-1\")\n",
    "    if not set([\"v1\", \"v2\"]).issubset(df.columns):\n",
    "        # Coba fallback: ambil dua kolom pertama\n",
    "        df = pd.read_csv(csv_path, encoding=\"latin-1\", header=0, names=[\"v1\", \"v2\", \"c3\", \"c4\", \"c5\"])\n",
    "\n",
    "    df = df[[\"v1\", \"v2\"]].rename(columns={\"v1\": \"label\", \"v2\": \"text\"})\n",
    "    # Bersihkan missing\n",
    "    df = df.dropna(subset=[\"label\", \"text\"])\n",
    "\n",
    "    # Hilangkan white-space kosong\n",
    "    df[\"text\"] = df[\"text\"].astype(str).str.strip()\n",
    "    df[\"label\"] = df[\"label\"].astype(str).str.strip()\n",
    "\n",
    "    # Filter label yang valid\n",
    "    df = df[df[\"label\"].isin([\"ham\", \"spam\"])]\n",
    "\n",
    "    X = df[\"text\"]\n",
    "    y = df[\"label\"]\n",
    "    return X, y\n",
    "\n",
    "def build_pipeline_count(stop_words: str = \"english\") -> Pipeline:\n",
    "    \"\"\"\n",
    "    Pipeline: CountVectorizer(stop_words='english') + MultinomialNB\n",
    "    \"\"\"\n",
    "    return Pipeline(\n",
    "        steps=[\n",
    "            (\"vec\", CountVectorizer(stop_words=stop_words)),\n",
    "            (\"clf\", MultinomialNB()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def build_pipeline_tfidf(stop_words: str = \"english\") -> Pipeline:\n",
    "    \"\"\"\n",
    "    Pipeline: TfidfVectorizer(stop_words='english') + MultinomialNB\n",
    "    \"\"\"\n",
    "    return Pipeline(\n",
    "        steps=[\n",
    "            (\"vec\", TfidfVectorizer(stop_words=stop_words)),\n",
    "            (\"clf\", MultinomialNB()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def evaluate_model(name: str, pipe: Pipeline, X_test: pd.Series, y_test: pd.Series) -> EvalResult:\n",
    "    preds = pipe.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    # Buat report dict agar bisa ambil F1 khusus kelas 'spam' dan macro avg\n",
    "    report = classification_report(\n",
    "        y_test, preds, labels=[\"ham\", \"spam\"], target_names=[\"ham\", \"spam\"], output_dict=True, zero_division=0\n",
    "    )\n",
    "    f1_spam = report[\"spam\"][\"f1-score\"]\n",
    "    precision_spam = report[\"spam\"][\"precision\"]\n",
    "    recall_spam = report[\"spam\"][\"recall\"]\n",
    "    f1_macro = report[\"macro avg\"][\"f1-score\"]\n",
    "    cm = confusion_matrix(y_test, preds, labels=[\"ham\", \"spam\"])\n",
    "    return EvalResult(\n",
    "        name=name,\n",
    "        accuracy=acc,\n",
    "        f1_spam=f1_spam,\n",
    "        precision_spam=precision_spam,\n",
    "        recall_spam=recall_spam,\n",
    "        f1_macro=f1_macro,\n",
    "        report=report,\n",
    "        confusion=cm,\n",
    "    )\n",
    "\n",
    "def print_eval(result: EvalResult):\n",
    "    print(f\"\\n=== {result.name} ===\")\n",
    "    print(f\"Akurasi      : {result.accuracy:.4f}\")\n",
    "    print(f\"F1 (spam)    : {result.f1_spam:.4f}\")\n",
    "    print(f\"Precision(spam): {result.precision_spam:.4f}\")\n",
    "    print(f\"Recall  (spam): {result.recall_spam:.4f}\")\n",
    "    print(f\"F1 (macro)   : {result.f1_macro:.4f}\")\n",
    "    print(\"Confusion Matrix [rows=true, cols=pred] (labels=['ham','spam']):\")\n",
    "    print(result.confusion)\n",
    "    # Cetak classification report ringkas\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(pd.DataFrame(result.report).transpose().round(3))\n",
    "\n",
    "def main():\n",
    "    # 1) Muat data\n",
    "    X, y = load_spam_dataset(\"spam.csv\")\n",
    "\n",
    "    # 2) Split data: stratified agar proporsi ham/spam seimbang antara train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "        # Jika dataset sangat besar, bisa tambah random_state lain untuk replikasi lain\n",
    "    )\n",
    "\n",
    "    # 3) Bangun pipeline\n",
    "    count_pipe = build_pipeline_count(stop_words=\"english\")\n",
    "    tfidf_pipe = build_pipeline_tfidf(stop_words=\"english\")\n",
    "\n",
    "    # 4) Latih model\n",
    "    count_pipe.fit(X_train, y_train)\n",
    "    tfidf_pipe.fit(X_train, y_train)\n",
    "\n",
    "    # 5) Evaluasi\n",
    "    count_res = evaluate_model(\"MultinomialNB + CountVectorizer(stop_words='english')\", count_pipe, X_test, y_test)\n",
    "    tfidf_res = evaluate_model(\"MultinomialNB + TfidfVectorizer(stop_words='english')\", tfidf_pipe, X_test, y_test)\n",
    "\n",
    "    # 6) Tampilkan hasil\n",
    "    print_eval(count_res)\n",
    "    print_eval(tfidf_res)\n",
    "\n",
    "    # 7) Bandingkan: gunakan F1 untuk kelas spam sebagai metrik utama\n",
    "    better = \"CountVectorizer\" if count_res.f1_spam >= tfidf_res.f1_spam else \"TF-IDF\"\n",
    "    print(\"\\n=== Perbandingan & Kesimpulan ===\")\n",
    "    print(\n",
    "        f\"F1(spam) CountVectorizer: {count_res.f1_spam:.4f} | TF-IDF: {tfidf_res.f1_spam:.4f} | \"\n",
    "        f\"Pilihan terbaik (berdasarkan F1 kelas spam): {better}\"\n",
    "    )\n",
    "    # Tambahan: jika ingin berdasarkan akurasi atau macro-F1, bisa juga dibandingkan:\n",
    "    if count_res.accuracy != tfidf_res.accuracy:\n",
    "        print(\n",
    "            f\"Akurasi     CountVectorizer: {count_res.accuracy:.4f} | TF-IDF: {tfidf_res.accuracy:.4f}\"\n",
    "        )\n",
    "    if count_res.f1_macro != tfidf_res.f1_macro:\n",
    "        print(\n",
    "            f\"F1(macro)   CountVectorizer: {count_res.f1_macro:.4f} | TF-IDF: {tfidf_res.f1_macro:.4f}\"\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        \"\\nCatatan:\\n\"\n",
    "        \"- Multinomial Naive Bayes secara teori lebih cocok untuk fitur berbasis frekuensi/count (CountVectorizer),\\n\"\n",
    "        \"  sehingga sering kali CountVectorizer memberi F1 spam sedikit lebih baik daripada TF-IDF.\\n\"\n",
    "        \"- Namun, hasil aktual bisa berbeda tergantung split data. Gunakan cross-validation untuk gambaran lebih stabil.\\n\"\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
